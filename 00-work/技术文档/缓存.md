# 多级缓存
### 什么是多级缓存

多级缓存是一种**分层存储架构**，旨在通过组合不同存储介质的性能特性，构建成本与速度的最优平衡。
其核心架构通常包含三个层次：
- **L1 本地缓存（进程级-热缓存）**：基于应用内存（如 Caffeine、Guava、Map）。特点为**极低延迟**，适合拦截超高频热点请求。
- **L2 分布式缓存（集群级-温缓存）**：基于高速中间件（如 Redis）。特点为**高并发、高可用**，用于在多节点间共享数据，作为本地缓存未命中时的快速回源。
- **L3 持久化存储（服务级-冷缓存）**：基于数据库或对象存储（如 PGSQL、MinIO）。特点为**大容量、高可靠**，作为数据的最终落地与兜底保障。
 目标：**以空间换时间，以存储换计算**。用极低的缓存成本，屏蔽掉后端繁重的计算逻辑，实现系统的高吞吐与低延迟。
### 多级缓存与单级缓存的区别
| 维度          | 单级缓存 (Single-Level)         | 多级缓存 (Multi-Level)                | 核心差异解析                     |
| :---------- | :-------------------------- | :-------------------------------- | :------------------------- |
| **架构层次**    | **扁平化**：仅依赖单一介质（通常为 Redis）  | **立体化**：L1(本地) + L2(分布式) + L3(DB) | 多级缓存构建了存储梯度的速度与容量平衡。       |
| **性能 (RT)** | **中等**：受限于网络 I/O 与序列化开销     | **极致**：L1 命中时为内存纳秒级访问             | 多级缓存消除了高频热点数据的网络交互。        |
| **容量扩展**    | **有限**：扩容需垂直升级或集群扩容         | **弹性**：利用 L1 内存存热点，L2 存温数据        | 实现了“小内存抗大流量”的高性价比扩展。       |
| **系统保护**    | **单点风险**：缓存宕机直接穿透击垮后端（QPS）  | **分层防御**：L2 宕机时 L1 仍能抵挡部分洪峰       | 增强了系统的容灾能力与抗雪崩能力。          |
| **命中率策略**   | **静态均衡**：统一管理冷热数据，无法分层优化命中率 | **动态分层**：热点自动上浮至 L1，冷数据下沉         | 利用 LRU/LFU 算法实现了数据的自动分级存储。 |
- **LRU**：**Least Recently Used（最近最少使用）**
    含义：当缓存满时，优先淘汰 **最久未被访问的数据**。
    
- **LFU**：**Least Frequently Used（最不经常使用）**
    含义：当缓存满时，优先淘汰 **访问次数最少的数据**。
- **LRU** 关注 **时间维度**（最近是否使用过）。
- **LFU** 关注 **使用频率**（被使用次数多少）。
### 为什么需要多级缓存
1. **防止“重复生成”导致的 CPU 算力浪费（防抖）**
    - **场景**：由于本地内存（L1）空间有限，旧 Key 被淘汰后，同一张热点瓦片被多个用户同时请求。
    - **痛点**：如果没有 L1 缓存拦截，大量请求会穿透到 Redis，甚至穿透到生成层。虽然有“生成后上传 MinIO”的逻辑，但在 MinIO 写入完成前的这段时间窗口内，**后端 TIFF 引擎会收到多次重复的切片计算指令**，导致 CPU 飙升。
    - **价值**：L1 本地缓存锁住了最热的 Key，确保对于已生成的瓦片，计算层**0 次重复计算**，彻底保护 TIFF 引擎。
2. **消除生成流程中的“MinIO 路径查询”延迟**
    - **场景**：用户请求一个坐标，系统需要先判断“这张图之前生成过没”。
    - **痛点**：判断“图是否存在”最准确的方法是查 MinIO，但这涉及一次网络 I/O。对于这种“可能存在也可能不存在”的检查请求，网络开销太重。
    - **价值**：通过 L1/L2 缓存 Key，**将“是否存在”的检查搬到了内存里**。如果命中 Key，直接去拉 MinIO 图；如果未命中 Key，直接走 TIFF 生成流程，省去了每次请求都要去 MinIO 探路的网络开销。
3. **利用“Key 遗忘”机制，让内存服务真正的“活跃数据”**
    - **场景**：TMS 瓦片数据量巨大（亿级 Key），但本地内存很小（只能存几万个 Key）。
    - **痛点**：如果只存 Redis，每次都要跨网络；如果只存本地，内存不够用，且无法区分哪些是“最近有人看的”，哪些是“几个月前看过一次的”。
    - **价值**：多级缓存利用 LRU/LFU 策略自动管理 Key。**只有最近被频繁访问的 Key 才会留在 L1**，偶尔被访问的 Key 降级到 Redis。这样，本地宝贵的内存始终只为当前最活跃的用户服务，实现了 Key 查询效率的最大化。
### 多级缓存的架构设计
![[diagram.svg|600]]
结合 TMS 瓦片服务，常用架构：
#### 1. 第一层：本地内存缓存（L1）
- **存什么**：**最最热门的 Key 索引**。
- **角色**：它是系统的 **“极速反应部队”** 。因为是存在应用服务器的内存里，读取速度是纳秒级的，没有任何网络延迟。
- **作用**：专门拦截那些用户盯着不放的区域（比如市中心），确保这些重复请求连 Redis都不用去问，直接就在本地搞定。
#### 2. 第二层：Redis 分布式缓存（L2）
- **存什么**：**近期访问过的 Key 索引**。
- **角色**：它是系统的 **“共享索引库”** 。
- **作用**：本地内存（L1）太小，存不下所有数据。L1 没找到时，就来 L2 找。Redis 是集群共享的，无论请求打到哪台服务器，只要这张图最近被生成过，这里都能查到路径，避免重复去“动”原始的 TIFF 文件。
#### 3. 第三层：MinIO 对象存储（L3）
- **存什么**：**所有的 PNG 瓦片文件**。
- **角色**：它是系统的 **“永久大仓库”** 。
- **作用**：这里容量无限大，存放着已经生成好的全量瓦片图片。如果 Redis 里也没这个 Key，说明这图很久没人看了，或者还没生成，这时候我们才考虑去动用最底层的 TIFF 引擎去“现做”一张。
> **访问流程**：请求 → 内存 → Redis → 数据库 → 原始数据生成
### 缓存策略
针对 Key 索引与瓦片生成的不同阶段，我们采用差异化的控制策略：
- **索引粒度**：**单瓦片 Key**
    - 采用最小粒度的 `Z/X/Y` 坐标作为缓存 Key（如 `tile:12:2048:1021`）。
    - **优势**：控制精细。只有在某个具体瓦片被请求时，才去检查索引或生成文件，避免加载不需要的区域数据，最大化节省内存和带宽。
- **Key 更新与淘汰策略**：
    - **热点管理（LRU/LFU）**：本地内存（L1）空间有限，采用 LRU（最近最少使用）或 LFU（最不经常使用）算法，**自动淘汰“冷门 Key”**，确保内存只保留用户最常访问的瓦片索引。
    - **主动刷新（重生成机制）**：当底层的 GeoTIFF 源文件数据更新时，通过消息队列或广播机制，**主动清除对应的 Key 缓存**。这会迫使下一次请求重新走生成流程，产出最新的瓦片并覆盖 MinIO 中的旧文件。
- **瓦片生成策略**：
    - **按需生成（默认策略）**：遵循“懒加载”原则，只有当 Key 在缓存中**不存在**时，才触发读取 TIFF 并切片转 PNG 的逻辑，避免冷数据浪费计算资源。
### 技术实现
``
- **L1 本地缓存：Hutool - LFU Cache**
    - **角色**：高频热点 Key 拦截器。
    - **实现原理**：利用 Hutool 提供的 `Cache` 接口（底层基于 `HashMap` 实现 LFU 策略）。
    - **优势**：
        - **极简集成**：Hutool 轻量级，API 友好，避免了 Caffeine 等重型库的复杂配置。
        - **热点识别**：**LFU（最不经常使用）算法**非常适合地图场景。它能自动识别并锁死那些**访问频率极高**的瓦片，即使这些热点在短时间内没有被访问，也不会轻易被淘汰。
    - **劣势**：基于 Java 堆内存，受限于 JVM 内存大小，不适合存储海量的冷数据 Key。
- **L2 分布式缓存：Redis**
    - **角色**：共享索引库。
    - **功能**：
        - **跨节点共享**：所有服务节点共享同一份 Key 索引，避免重复的 TIFF 切片计算。
        - **全量覆盖**：作为本地 LFU 缓存的后备，容量远大于本地内存，存储近期活跃的 Key。
        - **消息通知**：利用 Pub/Sub 机制，在底层数据更新时广播“清除 Key”指令。
- **L3 持久化存储：MinIO**
    - **角色**：瓦片文件仓库。
    - **功能**：
        - **海量存储**：低成本存储 PB 级别的 PNG 瓦片文件。
        - **数据持久化**：作为 TIFF 切片结果的最终落地点，支持长时间存储和历史查询。
### 挑战与应对
![[Pasted image 20251225144903.png]]
在实际生产环境中有时会遇到缓存穿透、缓存击穿、缓存雪崩等异常场景，为了避免异常带来巨大损失，我们需要了解每种异常发生的原因以及解决方案，帮助提升系统可靠性和高可用。
#### 缓存穿透

---
##### 什么是缓存穿透？

缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍，然后返回空。

如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至击垮数据库系统。
##### 缓存穿透常用的解决方案
**（1）布隆过滤器（推荐）**
布隆过滤器（Bloom Filter，简称BF）由Burton Howard Bloom在1970年提出，是一种空间效率高的概率型数据结构。

**布隆过滤器专门用来检测集合中是否存在特定的元素。**

如果在平时我们要判断一个元素是否在一个集合中，通常会采用查找比较的方法，下面分析不同的数据结构查找效率：

- 采用线性表存储，查找时间复杂度为O(N)
- 采用平衡二叉排序树（AVL、红黑树）存储，查找时间复杂度为O(logN)
- 采用哈希表存储，考虑到哈希碰撞，整体时间复杂度也要O[log(n/m)]

当需要判断一个元素是否存在于海量数据集合中，不仅查找时间慢，还会占用大量存储空间。接下来看一下布隆过滤器如何解决这个问题。

**布隆过滤器设计思想**

布隆过滤器由一个长度为m比特的位数组（bit array）与k个哈希函数（hash function）组成的数据结构。位数组初始化均为0，所有的哈希函数都可以分别把输入数据尽量均匀地散列。

当要向布隆过滤器中插入一个元素时，该元素经过k个哈希函数计算产生k个哈希值，以哈希值作为位数组中的下标，将所有k个对应的比特值由0置为1。

当要查询一个元素时，同样将其经过哈希函数计算产生哈希值，然后检查对应的k个比特值：如果有任意一个比特为0，表明该元素一定不在集合中；如果所有比特均为1，表明该集合有可能性在集合中。为什么不是一定在集合中呢？因为不同的元素计算的哈希值有可能一样，会出现哈希碰撞，导致一个不存在的元素有可能对应的比特位为1，这就是所谓“假阳性”（false positive）。相对地，“假阴性”（false negative）在BF中是绝不会出现的。

总结一下：布隆过滤器认为不在的，一定不会在集合中；布隆过滤器认为在的，可能在也可能不在集合中。

举个例子：下图是一个布隆过滤器，共有18个比特位，3个哈希函数。集合中三个元素x，y，z通过三个哈希函数散列到不同的比特位，并将比特位置为1。当查询元素w时，通过三个哈希函数计算，发现有一个比特位的值为0，可以肯定认为该元素不在集合中。

[![](https://camo.githubusercontent.com/8efd1f41f2fd1dbed65582a339d7bb83f5fbfe02ccd606b055383561f5b6c37b/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f536d696c654c696f6e436f6465722f617373657473406d61696e2f3230323031302f32303230313032353231333832302e706e67)](https://camo.githubusercontent.com/8efd1f41f2fd1dbed65582a339d7bb83f5fbfe02ccd606b055383561f5b6c37b/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f536d696c654c696f6e436f6465722f617373657473406d61696e2f3230323031302f32303230313032353231333832302e706e67)

  

**布隆过滤器优缺点**

优点：

- 节省空间：不需要存储数据本身，只需要存储数据对应hash比特位
- 时间复杂度低：插入和查找的时间复杂度都为O(k)，k为哈希函数的个数

缺点：

- 存在假阳性：布隆过滤器判断存在，可能出现元素不在集合中；判断准确率取决于哈希函数的个数
- 不能删除元素：如果一个元素被删除，但是却不能从布隆过滤器中删除，这也是造成假阳性的原因了

**布隆过滤器适用场景**

- 爬虫系统url去重
- 垃圾邮件过滤
- 黑名单

**（2）返回空对象**

当缓存未命中，查询持久层也为空，可以将返回的空对象写到缓存中，这样下次请求该key时直接从缓存中查询返回空对象，请求不会落到持久层数据库。为了避免存储过多空对象，通常会给空对象设置一个过期时间。

这种方法会存在两个问题：

- 如果有大量的key穿透，缓存空对象会占用宝贵的内存空间。
- 空对象的key设置了过期时间，在这段时间可能会存在缓存和持久层数据不一致的场景。

## 缓存击穿

### 什么是缓存击穿？

缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。

### 缓存击穿危害

数据库瞬时压力骤增，造成大量请求阻塞。
### 如何解决

**使用互斥锁（mutex key）**

这种思路比较简单，就是让一个线程回写缓存，其他线程等待回写缓存线程执行完，重新读缓存即可。

[![](https://camo.githubusercontent.com/aeb579e29779f2836918518ba3a9d8949f46d5bdedae4a9b130cf1686d626c77/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f536d696c654c696f6e436f6465722f617373657473406d61696e2f3230323031302f32303230313032353231333933392e706e67)](https://camo.githubusercontent.com/aeb579e29779f2836918518ba3a9d8949f46d5bdedae4a9b130cf1686d626c77/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f536d696c654c696f6e436f6465722f617373657473406d61696e2f3230323031302f32303230313032353231333933392e706e67)

  

同一时间只有一个线程读数据库然后回写缓存，其他线程都处于阻塞状态。如果是高并发场景，大量线程阻塞势必会降低吞吐量。这种情况如何解决？大家可以在留言区讨论。

如果是分布式应用就需要使用分布式锁。

**热点数据永不过期**

永不过期实际包含两层意思：

- 物理不过期，针对热点key不设置过期时间
- 逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建

[![](https://camo.githubusercontent.com/fcb689ee7c34a7a6e4a4d63873cc78038239b8ba8df2d4827f448b5e56af9438/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f536d696c654c696f6e436f6465722f617373657473406d61696e2f3230323031302f32303230313032353231333935392e706e67)
 
从实战看这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，对于不追求严格强一致性的系统是可以接受的。
## 缓存雪崩

### 什么是缓存雪崩？

缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，请求直接落到数据库上，引起数据库压力过大甚至宕机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。
### 缓存雪崩解决方案

常用的解决方案有：

- 均匀过期
- 加互斥锁
- 缓存永不过期
- 双层缓存策略

（1）均匀过期

设置不同的过期时间，让缓存失效的时间点尽量均匀。通常可以为有效期增加随机值或者统一规划有效期。

（2）加互斥锁

跟缓存击穿解决思路一致，同一时间只让一个线程构建缓存，其他线程阻塞排队。

（3）缓存永不过期

跟缓存击穿解决思路一致，缓存在物理上永远不过期，用一个异步的线程更新缓存。

（4）双层缓存策略

使用主备两层缓存：

主缓存：有效期按照经验值设置，设置为主读取的缓存，主缓存失效后从数据库加载最新值。
备份缓存：有效期长，获取锁失败时读取的缓存，主缓存更新时需要同步更新备份缓存。

## 缓存降级

缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。

在项目实战中通常会将部分热点数据缓存到服务的内存中，这样一旦缓存出现异常，可以直接使用服务的内存数据，从而避免数据库遭受巨大压力。

降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。
#### 总结
- **多级缓存的核心本质**——以**分层存储**换**计算效率**。通过在 L1/L2/L3 间构建速度阶梯，将昂贵的“TIFF 切片计算”转化为廉价的“Key 索引读取”。
- **架构没有银弹**。引入多级缓存虽然提升了吞吐，但也带来了**数据一致性**和**系统复杂度**的挑战。技术选型的本质，是在特定场景下对**性能**与**复杂度**做最合理的权衡。

