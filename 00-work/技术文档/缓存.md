# 多级缓存
### 什么是多级缓存
多级缓存是一种**分层存储架构**，旨在通过组合不同存储介质的性能特性，构建成本与速度的最优平衡。
其核心架构通常包含三个层次：
- **L1 本地缓存（进程级）**：基于应用内存（如 Caffeine、Guava）。特点为**极低延迟**，适合拦截超高频热点请求。
- **L2 分布式缓存（集群级）**：基于高速中间件（如 Redis）。特点为**高并发、高可用**，用于在多节点间共享数据，作为本地缓存未命中时的快速回源。
- **L3 持久化存储（服务级）**：基于数据库或对象存储（如 MySQL、MinIO）。特点为**大容量、高可靠**，作为数据的最终落地与兜底保障。
 目标：**以空间换时间，以存储换计算**。用极低的缓存成本，屏蔽掉后端繁重的计算逻辑，实现系统的高吞吐与低延迟。
### 多级缓存与单级缓存的区别
| 维度 | 单级缓存 (Single-Level) | 多级缓存 (Multi-Level) | 核心差异解析 |
| :--- | :--- | :--- | :--- |
| **架构层次** | **扁平化**：仅依赖单一介质（通常为 Redis） | **立体化**：L1(本地) + L2(分布式) + L3(DB) | 多级缓存构建了存储梯度的速度与容量平衡。 |
| **性能 (RT)** | **中等**：受限于网络 I/O 与序列化开销 | **极致**：L1 命中时为内存纳秒级访问 | 多级缓存消除了高频热点数据的网络交互。 |
| **容量扩展** | **有限**：扩容需垂直升级或集群扩容，成本高 | **弹性**：利用 L1 内存存热点，L2 存温数据 | 实现了“小内存抗大流量”的高性价比扩展。 |
| **系统保护** | **单点风险**：缓存宕机直接穿透击垮后端 | **分层防御**：L2 宕机时 L1 仍能抵挡部分洪峰 | 增强了系统的容灾能力与抗雪崩能力。 |
| **命中率策略** | **静态均衡**：无法区分冷热数据 | **动态分层**：热点自动上浮至 L1，冷数据下沉 | 利用 LRU/LFU 算法实现了数据的自动分级存储。 |
### 为什么需要多级缓存
1. **防止“重复生成”导致的 CPU 算力浪费（防抖）**
    - **场景**：由于本地内存（L1）空间有限，旧 Key 被淘汰后，同一张热点瓦片被多个用户同时请求。
    - **痛点**：如果没有 L1 缓存拦截，大量请求会穿透到 Redis，甚至穿透到生成层。虽然有“生成后上传 MinIO”的逻辑，但在 MinIO 写入完成前的这段时间窗口内，**后端 TIFF 引擎会收到多次重复的切片计算指令**，导致 CPU 飙升。
    - **价值**：L1 本地缓存锁住了最热的 Key，确保对于已生成的瓦片，计算层**0 次重复计算**，彻底保护 TIFF 引擎。
2. **消除生成流程中的“MinIO 路径查询”延迟**
    - **场景**：用户请求一个坐标，系统需要先判断“这张图之前生成过没”。
    - **痛点**：判断“图是否存在”最准确的方法是查 MinIO，但这涉及一次网络 I/O。对于这种“可能存在也可能不存在”的检查请求，网络开销太重。
    - **价值**：通过 L1/L2 缓存 Key，**将“是否存在”的检查搬到了内存里**。如果命中 Key，直接去拉 MinIO 图；如果未命中 Key，直接走 TIFF 生成流程，省去了每次请求都要去 MinIO 探路的网络开销。
3. **利用“Key 遗忘”机制，让内存服务真正的“活跃数据”**
    - **场景**：TMS 瓦片数据量巨大（亿级 Key），但本地内存很小（只能存几万个 Key）。
    - **痛点**：如果只存 Redis，每次都要跨网络；如果只存本地，内存不够用，且无法区分哪些是“最近有人看的”，哪些是“几个月前看过一次的”。
    - **价值**：多级缓存利用 LRU/LFU 策略自动管理 Key。**只有最近被频繁访问的 Key 才会留在 L1**，偶尔被访问的 Key 降级到 Redis。这样，本地宝贵的内存始终只为当前最活跃的用户服务，实现了 Key 查询效率的最大化。
### 多级缓存的架构设计
结合 TMS 瓦片服务，常用架构：
1. **内存缓存（第一层）**
    - 存储热点瓦片
    - 快速响应，命中率高
2. **Redis 分布式缓存（第二层）**
    - 热点数据共享，支持集群扩展
    - 适合多节点服务
3. **数据库 / 对象存储（第三层）**
    - 已生成瓦片的持久存储
    - 容量大，支持历史数据和冷数据访问

> **访问流程**：请求 → 内存 → Redis → 数据库 → 原始数据生成
### 缓存策略
- **粒度**：单瓦片 vs 瓦片区域
- **更新策略**：
    - TTL（过期自动刷新）
    - LRU / LFU（热点管理）
    - 主动刷新（数据更新时重新生成瓦片）
- **预生成策略**：
    - 热点区域批量生成
    - 异步任务生成冷数据瓦片
### 技术实现
- **内存缓存**：Caffeine / Guava Cache
    - 优势：极快响应，适合高频请求
    - 劣势：容量有限
- **Redis 缓存**：
    - 集群支持，跨节点共享
    - 支持过期策略、淘汰策略、队列通知刷新
- **数据库 / 持久化存储**：
    - SQL/NoSQL 或对象存储（MinIO、Ceph）
    - 支持长时间存储和历史瓦片查询
### 挑战与应对
#### 缓存一致性
- 瓦片更新时保证各层缓存同步
- 可采用主动更新 + TTL 双重机制
#### 缓存击穿
- 热点瓦片失效瞬间大量请求打到后端
- 解决方案：互斥锁 / 请求排队 / 预生成
#### 缓存雪崩
- 大量缓存同时过期导致瞬时高并发
- 解决方案：过期时间错开、随机 TTL
